---
title: "Correlated predictors disrupt importance"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Correlated predictors disrupt importance}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(randomForest)
library(ggplot2)
library(caret)
library(spuriousimportance)
```

## Overview of our example dataset

Let's start with generating a dataset named `ds`.

```{r ds}
set.seed(17)
ds <- generate_dataset()
```

Among five predictor variables `v`, `w`, `x`, `y`, and `z` in the dataset, the
first two are the most important for the regression of a response variable `r`,
as the following correlation matrix shows.

```{r cm, fig.width = 7, fig.height = 7}
graphics::pairs(r ~ v + w + x + y + z, data = ds)
```

## Training a model that works as expected

First, we train a random forest for the regression of `r`.

```{r rf}
rf <- randomForest(r ~ v + w + x + y + z, data = ds, mtry = 2, ntree = 50, importance = TRUE)
```

The following code illustrates how well the trained model performs the
regression for a new dataset.
Its accuracy turns out to be satisfactory although we omit to present any
measurement of the accuracy.

```{r valid, fig.width = 7}
validate_regression <- function(rf) {
    newds <- generate_dataset()
    newres <- predict(rf, newdata = newds)
    ggplot(data.frame(x = newds$r, y = newres)) +
        geom_point(aes(x, y)) +
        geom_abline(intercept = 0, slope = 1, colour = "red", linetype = "dashed") +
        coord_fixed() +
        xlab("r") +
        ylab(expression(hat(r)))
}

validate_regression(rf)
```

`randomForest::importance()` extracts the importance matrix of predictors from
a given random forest.
Note that the function can calculate different measures of importance, depending
on argument `type`.
Calling it with `type = 1` returns a permutation importance using the mean squared
error (MSE) for each tree.

```{r imp1}
importance(rf, type = 1)
```

By default the permutation importance is normalized to be so-called a z-score.
On the other hand, if another parameter `scale = FALSE` is passed, we get a raw
(unscaled) importance as follows.

```{r imp1raw}
importance(rf, type = 1, scale = FALSE)
```

Calling the function with `type = 2` returns another type of importance defined
with a mean decrease in node impurity, which is measured by the residual sum of
squares (RSS) for regressors.

```{r imp2}
importance(rf, type = 2)
```

## For a regression with a reduced set of predictors

Here we will see what happens when excluding unimportant variables `y` and `z`
from the set of predictors.

```{r rf1, fig.width = 7}
ds1 <- generate_dataset()
rf1 <- randomForest(r ~ v + w + x, data = ds1, mtry = 2, ntree = 50, importance = TRUE)
validate_regression(rf1)
```

Now the resulting importance of `x`, computed by permutating OOB data, is higher
than that of `v` or `w` as follows.

```{r rimp1}
importance(rf1, type = 1)
```

Nevertheless the unscaled permutation importance does not suffer the bias.

```{r rimp1raw}
importance(rf1, type = 1, scale = FALSE)
```

The importance measured by the node impurity is also as expected.

```{r rimp2}
importance(rf1, type = 2)
```

## For a binary classification defined by ranks

Next, we will train a random forest for the binary classification of a response
variable `s`, which divides the rows of a generated dataset into two groups, "A"
and "B", of equal numbers, using `r`'s median as a cut-off.

```{r rf2}
ds2 <- generate_dataset()
rf2 <- randomForest(s ~ v + w + x + y + z, data = ds2, mtry = 2, ntree = 50, importance = TRUE)
```

The classification performed by the obtained model is of high accuracy, as follows.

```{r valid2}
validate_classification <- function(rf) {
    newds <- generate_dataset()
    newres <- predict(rf, newdata = newds)
    confusionMatrix(newres, newds$s)
}

validate_classification(rf2)
```

However `x`'s importance, computed from permutating OOB data, is higher than
`v`'s or `w`'s, again.

```{r cimp1}
importance(rf2, type = 1)
```

Yet, such reversal does not occur with the raw permutation importance

```{r cimp1raw}
importance(rf2, type = 1, scale = FALSE)
```

... nor with the one measured by the node impurity.

```{r cimp2}
importance(rf2, type = 2)
```

## Conclusion

The core of our trick to disrupt importance in this vignette is to include two
correlated predictors, `v` and `w`.
They are collinear in fact.
For your information, [1] explains the same issue of collinearity in predictors,
as well as how to deal with it.

Our examples show that high accuracy of the regression or classification
performed by a trained model does not imply that the resulting importance is
correct.
They also indicate that the unscaled permutation importance behaves more
preferably than the scaled does, which agrees with the statements found in [2]
and [3].

## References

[1] scikit-learn developers. Permutation Importance with Multicollinear or Correlated Features. https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance_multicollinear.html

[2] Strobl, C., Boulesteix, AL., Kneib, T. et al. Conditional variable importance for random forests. BMC Bioinformatics 9, 307 (2008). https://doi.org/10.1186/1471-2105-9-307

[3] Parr, T. et al. Beware Default Random Forest Importances. https://explained.ai/rf-importance/index.html

