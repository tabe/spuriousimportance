---
title: "Correlated predictors disrupt importance"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Correlated predictors disrupt importance}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(randomForest)
library(ggplot2)
library(caret)
library(spuriousimportance)
```

## Overview of our example dataset

Let's start with generating a dataset named `ds`.

```{r ds}
ds <- generate_dataset()
```

Among five predictor variables `v`, `w`, `x`, `y`, and `z` in the dataset, the
first two are the most important for the regression of a response variable `r`,
as the following correlation matrix shows.

```{r cm, fig.width = 7, fig.height = 7}
graphics::pairs(r ~ v + w + x + y + z, data = ds)
```

## Training a model that works as expected

First, we train a random forest for the regression of `r`.

```{r rf}
rf <- randomForest(r ~ v + w + x + y + z, data = ds, importance = TRUE)
```

The following code illustrates how well the trained model performs the
regression for a new dataset.
Its accuracy turns out to be satisfactory although we omit to present any
measurement of the accuracy.

```{r valid, fig.width = 7}
validate_regression <- function(rf) {
    newds <- generate_dataset()
    newres <- predict(rf, newdata = newds)
    ggplot(data.frame(x = newds$r, y = newres)) +
        geom_point(aes(x, y)) +
        geom_abline(intercept = 0, slope = 1, colour = "red", linetype = "dashed") +
        coord_fixed() +
        xlab("r") +
        ylab(expression(hat(r)))
}

validate_regression(rf)
```

`randomForest::importance()` extracts the importance matrix of predictors from
a given random forest.

```{r imp1}
importance(rf, type = 1)
```

Note that the function can calculate different measures of importance, depending
on argument `type`.

```{r imp2}
importance(rf, type = 2)
```

## For a regression with a reduced set of predictors

Next, we will see what happens when excluding unimportant variables `y` and `z`
from the set of predictors.

```{r rf1, fig.width = 7}
ds1 <- generate_dataset()
rf1 <- randomForest(r ~ v + w + x, data = ds1, importance = TRUE)
validate_regression(rf1)
```

Now the resulting importance of `x`, computed by permutating OOB data, is higher
than that of `v` or `w` as follows.

```{r rimp1}
importance(rf1, type = 1)
```

Still, the importance measured by the node impurity is as expected.

```{r rimp2}
importance(rf1, type = 2)
```

## For a binary classification divided by the median

Here we will train a random forest for the binary classification of a response
variable `s`, which divides the rows of a generated dataset into two groups, "A"
and "B", of equal numbers, using `r`'s median as a cut-off.

```{r rf2}
ds2 <- generate_dataset()
rf2 <- randomForest(s ~ v + w + x + y + z, data = ds2, importance = TRUE)
```

The classification performed by the obtained model is of high accuracy, as follows.

```{r valid2}
validate_classification <- function(rf) {
    newds <- generate_dataset()
    newres <- predict(rf, newdata = newds)
    confusionMatrix(newres, newds$s)
}

validate_classification(rf2)
```

However `x`'s importance, computed from permutating OOB data, is higher than
`v`'s or `w`'s, again.

```{r cimp1}
importance(rf2, type = 1)
```

Yet, the one measured by the node impurity is as expected.

```{r cimp2}
importance(rf2, type = 2)
```

## Conclusion

The core of our trick to disrupt importance in the above is to include two
correlated predictors, `v` and `w`. They are collinear in fact.
Our examples show that high accuracy of the regression or classification
performed by a trained model does not imply that the resulting importance is
correct.
